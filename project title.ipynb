{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "423060ba",
   "metadata": {},
   "source": [
    "# Project Title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5042972",
   "metadata": {},
   "source": [
    "-description-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac166938",
   "metadata": {},
   "source": [
    "## Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1db7c1",
   "metadata": {},
   "source": [
    "1. Importing modules\n",
    "\n",
    "2. Data processing\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab538325",
   "metadata": {},
   "source": [
    "## 1. Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d4f9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from zipfile import ZipFile\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852dbd75",
   "metadata": {},
   "source": [
    "## 2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7bb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a spark session.\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2681551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4210\n",
      "4210\n",
      "wake.up.matt\n"
     ]
    }
   ],
   "source": [
    "spark = init_spark()\n",
    "\n",
    "lines = spark.sparkContext.textFile('data/influencers.txt')\n",
    "\n",
    "# get category and username index\n",
    "headers = lines.take(2)\n",
    "header = headers[0]\n",
    "category_index = header.split(\"\\t\").index(\"Category\")\n",
    "username_index = header.split(\"\\t\").index(\"Username\")\n",
    "\n",
    "# filter travel influencers\n",
    "lines = lines.filter(lambda line: line not in headers)\n",
    "lines = lines.map(lambda line: line.split(\"\\t\"))\n",
    "travel_influencers = lines.filter(lambda line: line[category_index] == 'travel')\n",
    "# get all travel influencers IG username\n",
    "travel_usernames = travel_influencers.map(lambda line: line[username_index])\n",
    "\n",
    "print(travel_influencers.count())\n",
    "print(travel_usernames.count())\n",
    "print(travel_usernames.collect()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75e2fbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zip/', 'zip/test1.txt', 'zip/test2.txt', 'zip/test3.txt']\n",
      "zip/test1.txt\n",
      "zip/test2.txt\n"
     ]
    }
   ],
   "source": [
    "# TODO: reduce time complexity\n",
    "with ZipFile('data/post-metadata/fix.zip', 'r') as zipObject:\n",
    "    names = zipObject.namelist()\n",
    "    for file_name in names:\n",
    "        if any(i in file_name for i in travel_usernames.collect()):\n",
    "            # Extract a travel influencers post metadata from zip\n",
    "            zipObject.extract(file_name, 'data/post-metadata')\n",
    "            print('All the python files are extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the files\n",
    "#./data is where all the info files reside. Change the path accordingly\n",
    "df = spark.read.json('./data/*.info')\n",
    "rdd = df.rdd\n",
    "\n",
    "#functions to extract data from Row rdd\n",
    "def extract_location(row):\n",
    "    if row is not None:\n",
    "        return row['name'], row['id']\n",
    "    return '', ''\n",
    "\n",
    "def extract_hash_tags(row):\n",
    "    result = []\n",
    "    if row is not None:\n",
    "        for edges in (row['edges'] or []):\n",
    "            parts = edges['node']['text'].split()\n",
    "            result.extend([p.strip() for p in parts if p.strip().startswith('#')])\n",
    "    return result\n",
    "\n",
    "def extract_count_likes(row):\n",
    "    if row is None or row['count'] is None:\n",
    "        return 0\n",
    "\n",
    "    return row['count']\n",
    "\n",
    "def extract_owner_username(row):\n",
    "    if row is None or row['username'] is None:\n",
    "        return ''\n",
    "\n",
    "    return row['username']\n",
    "\n",
    "def create_post(row):\n",
    "    loc_name, loc_id = extract_location(row['location'])\n",
    "    hash_tags = extract_hash_tags(row['edge_media_to_caption'])\n",
    "    post_id = row['id'] or ''\n",
    "    count_likes = extract_count_likes(row['edge_media_preview_like'])\n",
    "    owner_username = extract_owner_username(row['owner'])\n",
    "    return {\n",
    "        'post_id': post_id,\n",
    "        'location_name' : loc_name,\n",
    "        'location_id' : loc_id,\n",
    "        'hash_tags': hash_tags,\n",
    "        'count_likes': count_likes,\n",
    "        'owner_username': owner_username\n",
    "    }\n",
    "\n",
    "#creates the post on json format with all field needed.\n",
    "rdd.map(lambda r: create_post(r)) #.collect() #add this if you want to see the data on your local"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
