{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81fb6acd",
   "metadata": {},
   "source": [
    "# InstaSpot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e68e8b",
   "metadata": {},
   "source": [
    "Our main goal is to be able to recommend new travel destinations to users based on their interest in travel posts on Instagram. To achieve this, we will explore different ways to build recommender systems. We will compare results between a content-based and a matrix factorization based collaborative filtering approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f2197",
   "metadata": {},
   "source": [
    "## Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386239ac",
   "metadata": {},
   "source": [
    "1. Importing modules\n",
    "  * Initialize spark session\n",
    "  * Define metadata\n",
    "2. Data processing\n",
    "  * Retrieve travel influencers  \n",
    "  * Extract travel post metadata\n",
    "  * Extract relevant fields\n",
    "  * Create dataframe\n",
    "3. Data Analysis\n",
    "  * Location\n",
    "  * Instagram users\n",
    "  * Caption\n",
    "  * Accessibility caption\n",
    "4. Content-Based Recommendation\n",
    "5. Latent Factor Models\n",
    "  * Model 1\n",
    "  * Model 2\n",
    "  * Model 3\n",
    "  * Model 4\n",
    "  * Model 5\n",
    "  * Model performances on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b0d91",
   "metadata": {},
   "source": [
    "## 1. Importing modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df323a6",
   "metadata": {},
   "source": [
    "First, let's import some libraries that we're going to use in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49dd0cb2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import shutil\n",
    "import difflib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import sum\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from deep_translator import GoogleTranslator\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002f765f",
   "metadata": {},
   "source": [
    "Let's also initialize our spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd1bad9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.ui.showConsoleProgress\", 'false') \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caa1da5f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/04 21:15:12 WARN Utils: Your hostname, cnmk.local resolves to a loopback address: 127.0.0.1; using 192.168.0.58 instead (on interface en0)\n",
      "22/04/04 21:15:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/04/04 21:15:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = init_spark()\n",
    "spark.sparkContext.setLogLevel(\"OFF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6c3864",
   "metadata": {},
   "source": [
    "Let's define some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ccf616e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# To modify accordingly\n",
    "INFO_PATH = 'data/info/'\n",
    "POST_PATH = 'data/post-metadata/'\n",
    "DATASET_PATH = 'data/post-metadata/*.info'\n",
    "INFLUENCER_TEXT_PATH = 'data/influencers.txt'\n",
    "LOCATIONS = {}\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d984c38",
   "metadata": {},
   "source": [
    "## 2. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5936c04",
   "metadata": {},
   "source": [
    "Our [dataset](https://sites.google.com/site/sbkimcv/dataset#h.4eo4r5p70z10) comes from Proceedings of The Web Conference (WWW 20), ACM, 2020, provided by Seungbae Kim.\n",
    "\n",
    "This dataset classified influencers into nine categories namely *beauty, family, fashion, fitness, food, interior, pet, travel, and others*. It contains 300 posts per influencer, so there are over 10 million Instagram posts where each influencer is categorized based on their post metadata. Each post metadata file is in JSON format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498bb193",
   "metadata": {},
   "source": [
    "### Retrieve travel influencers\n",
    "\n",
    "\n",
    "Since we're only interested in travel influencers, we will retrieve all usernames from the travel category using <code>influencers.txt</code> which contains a list of influencers with their Instagram username, category, the number of followers, followees, and posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e3d21b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total travel users: 4210\n"
     ]
    }
   ],
   "source": [
    "lines = spark.sparkContext.textFile(INFLUENCER_TEXT_PATH)\n",
    "\n",
    "# get category and username index\n",
    "headers = lines.take(2)\n",
    "header = headers[0]\n",
    "category_index = header.split(\"\\t\").index(\"Category\")\n",
    "username_index = header.split(\"\\t\").index(\"Username\")\n",
    "post_index = header.split(\"\\t\").index(\"#Posts\")\n",
    "\n",
    "# filter travel influencers\n",
    "lines = lines.filter(lambda line: line not in headers)\n",
    "lines = lines.map(lambda line: line.split(\"\\t\"))\n",
    "travel_influencers = lines.filter(lambda line: line[category_index] == 'travel')\n",
    "# get all travel influencers IG username\n",
    "travel_usernames = travel_influencers.map(lambda line: line[username_index])\n",
    "\n",
    "print('Total travel users:',travel_usernames.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3758428d",
   "metadata": {},
   "source": [
    "As we can see above, there were 4210 instagram users categorized as travel influencers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6927ac",
   "metadata": {},
   "source": [
    "### Extract travel post metadata \n",
    "Now let's go ahead and extract the post metadata of those users only. Each post metadata filename starts with a username followed by a post ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca07e4cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# file_list = os.listdir(INFO_PATH)\n",
    "\n",
    "# for name in travel_usernames.collect():\n",
    "#     st = f'.{name}..info$'\n",
    "#     p = re.compile(st, re.IGNORECASE)\n",
    "#     for f in file_list:\n",
    "#         if p.match(f):\n",
    "#             shutil.copy(f'{INFO_PATH}{f}', POST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb2dae",
   "metadata": {},
   "source": [
    "### Extract relevant fields\n",
    "Since there are more information than we need, we will extract relevant fields from the JSON files.\n",
    "\n",
    "The following fields are the ones we found the most relevant to our project:\n",
    "\n",
    "| Fields               | Description                                      |\n",
    "| :------------------- | :------------------------------------------------|\n",
    "| post_id              | ID of the instagram post                         |\n",
    "| owner_id             | owner id of instagram post                       |\n",
    "| owner_username       | owner username of instagram post                 |\n",
    "|accessibility_caption | describes what the post is about                 |\n",
    "|likes_count           | number of likes the post received                |\n",
    "|comments_count        | number of comments the post received             |\n",
    "|commenters_id         | ID list of users who commented on the post       |\n",
    "|commenters_username   | username list of users who commented on the post |\n",
    "|tagged_users_id       | ID list of tagged users on the post              |\n",
    "|tagged_users_username | username list of tagged users on the post        |\n",
    "|caption               | caption of the post                              |\n",
    "|hashtags              | hashtags from caption of the post                |\n",
    "|location_id           | location id of the post                          |\n",
    "|location_name         | location name of the post                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d82b33",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "Below are helper functions that will extract the required fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28dc5792",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# helper function to extract counts\n",
    "def extract_counts(row, field):\n",
    "    if field not in row:\n",
    "        return 0\n",
    "    if row[field] is None:\n",
    "        return 0\n",
    "    if 'count' not in row[field] or row[field]['count'] is None:\n",
    "        return 0\n",
    "    return int(row[field]['count'])\n",
    "\n",
    "# helper function to traverse user network\n",
    "def extract_nodes_from_edges(row, field, secondary_fields):\n",
    "    result = []\n",
    "    if field not in row or row[field] is None \\\n",
    "    or 'edges' not in row[field] or row[field]['edges'] is None:\n",
    "        return []\n",
    "\n",
    "    for edge in row[field]['edges']:\n",
    "        if 'node' in edge and edge['node']:\n",
    "            no_error = True\n",
    "            temp = edge['node']\n",
    "            for f in secondary_fields:\n",
    "                if f in temp and temp[f]:\n",
    "                    temp = temp[f]\n",
    "                else:\n",
    "                    no_error = False\n",
    "                    \n",
    "            if no_error:\n",
    "                result.append(temp)\n",
    " \n",
    "    return result\n",
    "\n",
    "# helper function to extract tagged users from caption\n",
    "def extract_tagged_users(caption):\n",
    "    tagged = []\n",
    "    if caption is None or len(caption) == 0:\n",
    "        return tagged\n",
    "    else: \n",
    "        for word in caption[0].split():\n",
    "            if word[0] == '@':\n",
    "                tagged.append(word[1:])\n",
    "        return tagged\n",
    "    \n",
    "# likes_count\n",
    "def likes(row):\n",
    "    return extract_counts(row, 'edge_media_preview_like')\n",
    "\n",
    "# comments_count\n",
    "def comments_count(row):\n",
    "    return extract_counts(row, 'edge_media_to_parent_comment')\n",
    "\n",
    "# tagged_users_id\n",
    "def extract_tagged_users_id(row):\n",
    "    tagged_ls = extract_nodes_from_edges(row, 'edge_media_to_tagged_user', ['user', 'id'])\n",
    "    return list(map(int, tagged_ls))\n",
    "\n",
    "# tagged_users_username\n",
    "def extract_tagged_users_username(row):\n",
    "    return extract_nodes_from_edges(row, 'edge_media_to_tagged_user', ['user', 'username'])\n",
    "\n",
    "# commenters_id\n",
    "def extract_commenters_id(row):\n",
    "    comm_ls = extract_nodes_from_edges(row, 'edge_media_to_parent_comment', ['owner', 'id'])\n",
    "    return list(map(int, comm_ls))\n",
    "\n",
    "# commenters_username\n",
    "def extract_commenters_username(row):\n",
    "    return extract_nodes_from_edges(row, 'edge_media_to_parent_comment', ['owner', 'username'])\n",
    "\n",
    "# hashtags\n",
    "def extract_hashtags(caption):\n",
    "    hashtags = []\n",
    "    if caption is None or len(caption) == 0:\n",
    "        return hashtags\n",
    "    else: \n",
    "        for word in caption[0].split():\n",
    "            if word[0] == '#':\n",
    "                hashtags.append(word[1:])\n",
    "        return hashtags\n",
    "\n",
    "# caption\n",
    "def extract_text_from_caption(row):\n",
    "    result = []\n",
    "    if 'edge_media_to_caption' not in row or row['edge_media_to_caption'] is None \\\n",
    "    or 'edges' not in row['edge_media_to_caption'] or row['edge_media_to_caption']['edges'] is None:\n",
    "        return []\n",
    "    \n",
    "    for edge in row['edge_media_to_caption']['edges']:\n",
    "        if 'node' in edge and edge['node'] and 'text' in edge['node']:\n",
    "            result.append(edge['node']['text'])\n",
    "    return result\n",
    "\n",
    "# location id, name\n",
    "def extract_location(row):\n",
    "    result = {\n",
    "        'location_name': '',\n",
    "        'location_id': ''\n",
    "    }\n",
    "    if 'location' in row and row['location']:\n",
    "        if 'name' in row['location'] and 'id' in row['location']:\n",
    "            result['location_name'] = row['location']['name']\n",
    "            result['location_id']   = int(row['location']['id'])\n",
    "        \n",
    "    return result\n",
    "\n",
    "# owner_id\n",
    "def extract_post_owner_id(row):\n",
    "    if 'owner' not in row or row['owner'] is None:\n",
    "        return ''\n",
    "\n",
    "    if 'id' not in row['owner'] or row['owner']['id'] is None:\n",
    "        return ''\n",
    "\n",
    "    return int(row['owner']['id'])\n",
    "\n",
    "# owner_username\n",
    "def extract_post_owner_username(row):\n",
    "    if 'owner' not in row or row['owner'] is None:\n",
    "        return ''\n",
    "    \n",
    "    if 'username' not in row['owner'] or row['owner']['username'] is None:\n",
    "        return ''\n",
    "\n",
    "    return row['owner']['username']\n",
    "\n",
    "# post_id\n",
    "def extract_post_id(row):\n",
    "    if 'id' not in row or row['id'] is None:\n",
    "        return ''\n",
    "    \n",
    "    return int(row['id'])\n",
    "\n",
    "# accessibility_caption\n",
    "def extract_accessibility_caption(row):\n",
    "    if 'accessibility_caption' not in row or row['accessibility_caption'] is None:\n",
    "        return ''\n",
    "    \n",
    "    return row['accessibility_caption']\n",
    "    \n",
    "# returns an RDD where each row is a json file \n",
    "def create_post_as_json(row):\n",
    "    post_id = extract_post_id(row)\n",
    "    location = extract_location(row)\n",
    "    owner_id = extract_post_owner_id(row)\n",
    "    owner_username = extract_post_owner_username(row)\n",
    "    caption = extract_text_from_caption(row)\n",
    "    hashtags = extract_hashtags(caption)\n",
    "    likes_count = likes(row)\n",
    "    tagged_users_id = extract_tagged_users_id(row)\n",
    "    tagged_users_username = extract_tagged_users_username(row) # TODO: ADD @ FROM CAPTIONS\n",
    "    commenters_id = extract_commenters_id(row)\n",
    "    commenters_username = extract_commenters_username(row)\n",
    "    comment_count = comments_count(row)\n",
    "    accessibility_caption = extract_accessibility_caption(row)\n",
    "    \n",
    "    return {\n",
    "        'post_id': post_id,\n",
    "        'owner_id': owner_id,\n",
    "        'owner_username': owner_username,\n",
    "        'location_id' : location['location_id'],\n",
    "        'location_name' : location['location_name'],\n",
    "        'likes_count': likes_count,\n",
    "        'comments_count': comment_count,\n",
    "        'commenters_id': commenters_id,\n",
    "        'commenters_username': commenters_username,\n",
    "        'tagged_users_id': tagged_users_id,\n",
    "        'tagged_users_username': tagged_users_username,\n",
    "        'caption': caption,\n",
    "        'hashtags': hashtags,\n",
    "        'accessibility_caption': accessibility_caption     \n",
    "    }\n",
    "\n",
    "# converts a json file into tuples\n",
    "def convert_json_to_tuple(row):\n",
    "    post_id = row['post_id']\n",
    "    location_name = row['location_name']\n",
    "    location_id = row['location_id']\n",
    "    likes_count = row['likes_count']\n",
    "    owner_id = row['owner_id']\n",
    "    owner_username = row['owner_username']\n",
    "    caption = row['caption']\n",
    "    hashtags = row['hashtags']\n",
    "    tagged_users_id = row['tagged_users_id']\n",
    "    tagged_users_username = row['tagged_users_username']\n",
    "    commenters_id = row['commenters_id']\n",
    "    commenters_username = row['commenters_username']\n",
    "    accessibility_caption = row['accessibility_caption']\n",
    "    comment_count = row['comments_count']\n",
    "    return (post_id, owner_id, owner_username, location_id, location_name,\n",
    "            likes_count, comment_count, commenters_id, commenters_username,\n",
    "            tagged_users_id, tagged_users_username, caption, hashtags,\n",
    "            accessibility_caption)\n",
    "\n",
    "# when exporting the data to CSV, it doesn't allow arrays, so the they need to be converted to strings\n",
    "def flatten_json_lists(row):\n",
    "    row['caption'] = '. '.join(row['caption'])\n",
    "    row['hashtags'] = ', '.join(row['hashtags'])\n",
    "#     row['tagged_users_id'] =  ', '.join(row['tagged_users_id'])\n",
    "    row['tagged_users_username'] =  ', '.join(row['tagged_users_username'])\n",
    "#     row['commenters_id'] = ', '.join(row['commenters_id'])\n",
    "    row['commenters_username'] =  ', '.join(row['commenters_username'])\n",
    "    return row\n",
    "\n",
    "# function that replaces \"\\r\" with \"\\n\"\n",
    "def remove_carry_returns(row):\n",
    "    row['caption'] = row['caption'].replace('\\r', '').replace('\\n', ' ')\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334bc260",
   "metadata": {},
   "source": [
    "Now that we are all set, we will read all JSON files into an RDD,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "264f7a48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.json(DATASET_PATH)\n",
    "rdd =  df.rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc5ba1a",
   "metadata": {},
   "source": [
    "We will then map our helper functions to extract the neccessary fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1704d654",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#transform data to the needed format\n",
    "rdd = rdd.map(lambda r: create_post_as_json(r)).\\\n",
    "    map(lambda r: flatten_json_lists(r)).\\\n",
    "    map(lambda r: remove_carry_returns(r)).\\\n",
    "    map(lambda r: convert_json_to_tuple(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504025c8",
   "metadata": {},
   "source": [
    "And finally convert our RDD into a dataframe with the following schema to better explore our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "446ac706",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "schema = ['post_id', 'owner_id', 'owner_username','location_id', 'location_name',\n",
    "          'likes_count', 'comments_count', 'commenters_id', 'commenters_username',\n",
    "          'tagged_users_id', 'tagged_users_username', 'caption', 'hashtags',\n",
    "          'accessibility_caption']\n",
    "\n",
    "df = rdd.toDF(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50a2ce5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68353"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ee9274",
   "metadata": {},
   "source": [
    "As we can see above, we collected 68,353 post metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c03f4",
   "metadata": {},
   "source": [
    "Let's have a look at the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9672d4cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>owner_id</th>\n",
       "      <th>owner_username</th>\n",
       "      <th>location_id</th>\n",
       "      <th>location_name</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>commenters_id</th>\n",
       "      <th>commenters_username</th>\n",
       "      <th>tagged_users_id</th>\n",
       "      <th>tagged_users_username</th>\n",
       "      <th>caption</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>accessibility_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1875572106509410527</td>\n",
       "      <td>398526345</td>\n",
       "      <td>thetravellingbeautyqueen</td>\n",
       "      <td>5.670778e+08</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>11813</td>\n",
       "      <td>151</td>\n",
       "      <td>[1148667561, 177036590, 191099913, 308451883, ...</td>\n",
       "      <td>normandothemagician, waelalteen, remybaghdady,...</td>\n",
       "      <td>[28760386, 194294592, 215212085, 306780945, 36...</td>\n",
       "      <td>mexicotravel, peperlupe, camillawithlove, yuca...</td>\n",
       "      <td>My newest - 21 st magazine cover😊👸🏼👑📸❤ Mid Tim...</td>\n",
       "      <td>thetravellingbeautyqueen, lenkajosefiova, cove...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1829719472242373040</td>\n",
       "      <td>3597572</td>\n",
       "      <td>pinnywooh</td>\n",
       "      <td>2.563929e+08</td>\n",
       "      <td>Valley of Fire State Park</td>\n",
       "      <td>7163</td>\n",
       "      <td>219</td>\n",
       "      <td>[318445882, 1691724710, 3032894450, 254938180,...</td>\n",
       "      <td>mrs_vernova, giingerann, misssebyaha, puercoes...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Обещала вам пост, как выглядит типичный рабочи...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1881175916568618668</td>\n",
       "      <td>756368100</td>\n",
       "      <td>putopis</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>936</td>\n",
       "      <td>41</td>\n",
       "      <td>[176130500, 768082182, 6113944286, 5325916, 28...</td>\n",
       "      <td>naturetalker, zeljka_dja, travelbookcroatia, a...</td>\n",
       "      <td>[21943587, 23947096, 181415118, 215124008, 276...</td>\n",
       "      <td>huffpost, natgeotravel, foodandwine, jetsettim...</td>\n",
       "      <td>Rovinj is a town full of beautiful colors and ...</td>\n",
       "      <td>Podravka, vegetamaestro, rovinj, istria, cooli...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1802821674903711318</td>\n",
       "      <td>17205419</td>\n",
       "      <td>mahfamily5</td>\n",
       "      <td>2.022789e+14</td>\n",
       "      <td>Edmonds Marina Beach Park</td>\n",
       "      <td>120</td>\n",
       "      <td>29</td>\n",
       "      <td>[17205419, 17205419, 7008936574, 7144133477, 7...</td>\n",
       "      <td>mahfamily5, mahfamily5, glampfam, mcculloughsw...</td>\n",
       "      <td>[716750476, 1024912394, 1553633873, 3288300648...</td>\n",
       "      <td>momswithcameras, king5evening, edmondsdowntown...</td>\n",
       "      <td>Mia had a great morning despite the little sle...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1938656069423140660</td>\n",
       "      <td>2088079721</td>\n",
       "      <td>frabjous_existence</td>\n",
       "      <td>1.300522e+15</td>\n",
       "      <td>The Rooftop at Pier 17</td>\n",
       "      <td>288</td>\n",
       "      <td>46</td>\n",
       "      <td>[6774931332, 2088079721, 5533385199, 690045046...</td>\n",
       "      <td>giu_lucchi, frabjous_existence, lewisnation.lo...</td>\n",
       "      <td>[18078794, 19009288, 21723588, 27410259, 20814...</td>\n",
       "      <td>nycgo, nbcnewyork, nymag, uonewyork, streeteas...</td>\n",
       "      <td>ᴛᴀsᴛʏ ᴛʜᴜʀsᴅᴀʏ, ᴀɴᴅ ᴛᴏᴅᴀʏ ᴡᴇ ᴠᴇɴᴛᴜʀᴇ ᴅᴏᴡɴ ᴛᴏ ᴘ...</td>\n",
       "      <td>skatetheskyline</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1910816411687530750</td>\n",
       "      <td>2149187649</td>\n",
       "      <td>vivircorriendo</td>\n",
       "      <td>2.150268e+08</td>\n",
       "      <td>Donostia-San Sebastián, Spain</td>\n",
       "      <td>1667</td>\n",
       "      <td>36</td>\n",
       "      <td>[264336303, 250260, 7915197480, 1024511319, 10...</td>\n",
       "      <td>soyloquevivo, vaboom, carloantoniobaroni, davi...</td>\n",
       "      <td>[24570782, 29873342, 32188770, 45949544, 20015...</td>\n",
       "      <td>raulgomez82, odlo, igor_quijano, mariamainez, ...</td>\n",
       "      <td>EMBAJADORA 50/50/25 . Gracias a la Organizació...</td>\n",
       "      <td>bss505025, VivircorRiendo, QueAReirNoTeGaneNad...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022997046060861046</td>\n",
       "      <td>5851437</td>\n",
       "      <td>griffinthall</td>\n",
       "      <td>2.346263e+08</td>\n",
       "      <td>Coachella, California</td>\n",
       "      <td>1064</td>\n",
       "      <td>31</td>\n",
       "      <td>[21787221, 9053350, 38223425, 22831662, 207836...</td>\n",
       "      <td>dyluxe, chasefisher, aaron.griver, markweeeene...</td>\n",
       "      <td>[4724305, 5851437, 5878398, 7641344, 8138633, ...</td>\n",
       "      <td>andiefitzgerald, griffinthall, sarah_cothren, ...</td>\n",
       "      <td>Such an incredible #Coachella weekend with the...</td>\n",
       "      <td>Coachella, livefree, puravidabracelets, pvtake...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1883554250934263592</td>\n",
       "      <td>513006206</td>\n",
       "      <td>zitamaleki</td>\n",
       "      <td>1.481296e+15</td>\n",
       "      <td>Bittersweet</td>\n",
       "      <td>1429</td>\n",
       "      <td>33</td>\n",
       "      <td>[7592647359, 651681146, 2124063267, 3949779833...</td>\n",
       "      <td>_baran.mystyle_, almaa_food, fafa.trv, h._zahr...</td>\n",
       "      <td>[6942978, 20158039, 20528476, 145363808, 17689...</td>\n",
       "      <td>express, fendi, pierrecardintr, swarovski, cha...</td>\n",
       "      <td>حتمن یادتون میاد که یه موقعی این بحث خیلی داغ ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1997024571324339641</td>\n",
       "      <td>1539201055</td>\n",
       "      <td>high_vis</td>\n",
       "      <td>3.003208e+06</td>\n",
       "      <td>American Airlines Center</td>\n",
       "      <td>373</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[6114566, 13657382, 14536518, 179450081, 21943...</td>\n",
       "      <td>dallasmavs, valerie_ramirez, cyntgm, sportsill...</td>\n",
       "      <td>Killer @dallasmavs halftime show by @inthelab2...</td>\n",
       "      <td>Truemaverick, dallasmavericks, dallasmavsshop</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013304121478023187</td>\n",
       "      <td>199833517</td>\n",
       "      <td>viaja_inspirado</td>\n",
       "      <td>2.148811e+08</td>\n",
       "      <td>Valparaíso, Chile</td>\n",
       "      <td>1162</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[199833517, 260190008, 319958459, 483633802, 1...</td>\n",
       "      <td>viaja_inspirado, sientevalpo, chiletravel, fco...</td>\n",
       "      <td>Valparaiso de mi amor ❤️🎶 Que lindo es Valpara...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               post_id    owner_id            owner_username   location_id  \\\n",
       "0  1875572106509410527   398526345  thetravellingbeautyqueen  5.670778e+08   \n",
       "1  1829719472242373040     3597572                 pinnywooh  2.563929e+08   \n",
       "2  1881175916568618668   756368100                   putopis           NaN   \n",
       "3  1802821674903711318    17205419                mahfamily5  2.022789e+14   \n",
       "4  1938656069423140660  2088079721        frabjous_existence  1.300522e+15   \n",
       "5  1910816411687530750  2149187649            vivircorriendo  2.150268e+08   \n",
       "6  2022997046060861046     5851437              griffinthall  2.346263e+08   \n",
       "7  1883554250934263592   513006206                zitamaleki  1.481296e+15   \n",
       "8  1997024571324339641  1539201055                  high_vis  3.003208e+06   \n",
       "9  2013304121478023187   199833517           viaja_inspirado  2.148811e+08   \n",
       "\n",
       "                   location_name  likes_count  comments_count  \\\n",
       "0                         Mexico        11813             151   \n",
       "1      Valley of Fire State Park         7163             219   \n",
       "2                                         936              41   \n",
       "3      Edmonds Marina Beach Park          120              29   \n",
       "4         The Rooftop at Pier 17          288              46   \n",
       "5  Donostia-San Sebastián, Spain         1667              36   \n",
       "6          Coachella, California         1064              31   \n",
       "7                    Bittersweet         1429              33   \n",
       "8       American Airlines Center          373               0   \n",
       "9              Valparaíso, Chile         1162               0   \n",
       "\n",
       "                                       commenters_id  \\\n",
       "0  [1148667561, 177036590, 191099913, 308451883, ...   \n",
       "1  [318445882, 1691724710, 3032894450, 254938180,...   \n",
       "2  [176130500, 768082182, 6113944286, 5325916, 28...   \n",
       "3  [17205419, 17205419, 7008936574, 7144133477, 7...   \n",
       "4  [6774931332, 2088079721, 5533385199, 690045046...   \n",
       "5  [264336303, 250260, 7915197480, 1024511319, 10...   \n",
       "6  [21787221, 9053350, 38223425, 22831662, 207836...   \n",
       "7  [7592647359, 651681146, 2124063267, 3949779833...   \n",
       "8                                                 []   \n",
       "9                                                 []   \n",
       "\n",
       "                                 commenters_username  \\\n",
       "0  normandothemagician, waelalteen, remybaghdady,...   \n",
       "1  mrs_vernova, giingerann, misssebyaha, puercoes...   \n",
       "2  naturetalker, zeljka_dja, travelbookcroatia, a...   \n",
       "3  mahfamily5, mahfamily5, glampfam, mcculloughsw...   \n",
       "4  giu_lucchi, frabjous_existence, lewisnation.lo...   \n",
       "5  soyloquevivo, vaboom, carloantoniobaroni, davi...   \n",
       "6  dyluxe, chasefisher, aaron.griver, markweeeene...   \n",
       "7  _baran.mystyle_, almaa_food, fafa.trv, h._zahr...   \n",
       "8                                                      \n",
       "9                                                      \n",
       "\n",
       "                                     tagged_users_id  \\\n",
       "0  [28760386, 194294592, 215212085, 306780945, 36...   \n",
       "1                                                 []   \n",
       "2  [21943587, 23947096, 181415118, 215124008, 276...   \n",
       "3  [716750476, 1024912394, 1553633873, 3288300648...   \n",
       "4  [18078794, 19009288, 21723588, 27410259, 20814...   \n",
       "5  [24570782, 29873342, 32188770, 45949544, 20015...   \n",
       "6  [4724305, 5851437, 5878398, 7641344, 8138633, ...   \n",
       "7  [6942978, 20158039, 20528476, 145363808, 17689...   \n",
       "8  [6114566, 13657382, 14536518, 179450081, 21943...   \n",
       "9  [199833517, 260190008, 319958459, 483633802, 1...   \n",
       "\n",
       "                               tagged_users_username  \\\n",
       "0  mexicotravel, peperlupe, camillawithlove, yuca...   \n",
       "1                                                      \n",
       "2  huffpost, natgeotravel, foodandwine, jetsettim...   \n",
       "3  momswithcameras, king5evening, edmondsdowntown...   \n",
       "4  nycgo, nbcnewyork, nymag, uonewyork, streeteas...   \n",
       "5  raulgomez82, odlo, igor_quijano, mariamainez, ...   \n",
       "6  andiefitzgerald, griffinthall, sarah_cothren, ...   \n",
       "7  express, fendi, pierrecardintr, swarovski, cha...   \n",
       "8  dallasmavs, valerie_ramirez, cyntgm, sportsill...   \n",
       "9  viaja_inspirado, sientevalpo, chiletravel, fco...   \n",
       "\n",
       "                                             caption  \\\n",
       "0  My newest - 21 st magazine cover😊👸🏼👑📸❤ Mid Tim...   \n",
       "1  Обещала вам пост, как выглядит типичный рабочи...   \n",
       "2  Rovinj is a town full of beautiful colors and ...   \n",
       "3  Mia had a great morning despite the little sle...   \n",
       "4  ᴛᴀsᴛʏ ᴛʜᴜʀsᴅᴀʏ, ᴀɴᴅ ᴛᴏᴅᴀʏ ᴡᴇ ᴠᴇɴᴛᴜʀᴇ ᴅᴏᴡɴ ᴛᴏ ᴘ...   \n",
       "5  EMBAJADORA 50/50/25 . Gracias a la Organizació...   \n",
       "6  Such an incredible #Coachella weekend with the...   \n",
       "7  حتمن یادتون میاد که یه موقعی این بحث خیلی داغ ...   \n",
       "8  Killer @dallasmavs halftime show by @inthelab2...   \n",
       "9  Valparaiso de mi amor ❤️🎶 Que lindo es Valpara...   \n",
       "\n",
       "                                            hashtags accessibility_caption  \n",
       "0  thetravellingbeautyqueen, lenkajosefiova, cove...                        \n",
       "1                                                                           \n",
       "2  Podravka, vegetamaestro, rovinj, istria, cooli...                        \n",
       "3                                                                           \n",
       "4                                    skatetheskyline                        \n",
       "5  bss505025, VivircorRiendo, QueAReirNoTeGaneNad...                        \n",
       "6  Coachella, livefree, puravidabracelets, pvtake...                        \n",
       "7                                                                           \n",
       "8      Truemaverick, dallasmavericks, dallasmavsshop                        \n",
       "9                                                                           "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77004f",
   "metadata": {},
   "source": [
    "## 3. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10467138",
   "metadata": {},
   "source": [
    "So far we have been discovering and structuring our data. Our next step will be to perform a descriptive data analysis to have a better summary our features.\n",
    "\n",
    "Since performing action functions on this huge amount of data can be costly, we will only focus on the most important features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26885c46",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae0f5f",
   "metadata": {},
   "source": [
    "Let's have a look at the number of unique values in <code>location_id</code> and <code>location_name</code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9561eae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_id:  24853\n"
     ]
    }
   ],
   "source": [
    "print(\"location_id: \", df.select(\"location_id\").distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05909299",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_name:  24068\n"
     ]
    }
   ],
   "source": [
    "print(\"location_name: \", df.select(\"location_name\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d9881",
   "metadata": {},
   "source": [
    "Since the number unique values of <code>location_id</code> and <code>location_name</code> differ, we can deduce that there are some post metadata that have missing location info. \n",
    "\n",
    "Let's count how many times <code>location_id</code> and <code>location_name</code> are both missing in a post metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70fbbb2c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19760"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"location_id\").isNull()) & (col(\"location_name\") == '')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba7b32",
   "metadata": {},
   "source": [
    "Let's also count the number of times a post metadata has <code>location_name</code> missing but has a <code>location_id</code> and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f89a889e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"location_id\").isNotNull()) & (col(\"location_name\") == '')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0893a699",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"location_id\").isNull()) & (col(\"location_name\") != '')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84419ff2",
   "metadata": {},
   "source": [
    "Based on the missing counts above, we noticed that there are 19,760 post metadata with no information about its location, therefore we will drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6df7eaef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df[(df.location_id.isNotNull()) & (df.location_name != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8964110",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19760 rows dropped successfully!\n"
     ]
    }
   ],
   "source": [
    "assert df.count() == (68353-19760)\n",
    "print(\"19760 rows dropped successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a20ef",
   "metadata": {},
   "source": [
    "### Instagram Users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3655e3",
   "metadata": {},
   "source": [
    "Let's check out <code>owner_id</code> and <code>owner_username</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "471c7313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"owner_id\").isNull()) & (col(\"owner_username\") == '')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2df1a6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"owner_id\").isNotNull()) & (col(\"owner_username\") == '')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "457ca131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"owner_id\").isNull()) & (col(\"owner_username\") != '')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b4dc3",
   "metadata": {},
   "source": [
    "Based on the above, we noticed that there are no missing information about the owner of the post, therefore no rows needs to be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87749be3",
   "metadata": {},
   "source": [
    "### Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d264d6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def translate_(c):\n",
    "    if c == '':\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            return GoogleTranslator(source='auto', target='en').translate(c)\n",
    "        except:\n",
    "            return c\n",
    "        \n",
    "translate = udf(translate_, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc763fe1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(col(\"caption\") == '').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdeb1118",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My newest - 21 st magazine cover😊👸🏼👑📸❤ Mid Tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Обещала вам пост, как выглядит типичный рабочи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mia had a great morning despite the little sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ᴛᴀsᴛʏ ᴛʜᴜʀsᴅᴀʏ, ᴀɴᴅ ᴛᴏᴅᴀʏ ᴡᴇ ᴠᴇɴᴛᴜʀᴇ ᴅᴏᴡɴ ᴛᴏ ᴘ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMBAJADORA 50/50/25 . Gracias a la Organizació...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Such an incredible #Coachella weekend with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>حتمن یادتون میاد که یه موقعی این بحث خیلی داغ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption\n",
       "0  My newest - 21 st magazine cover😊👸🏼👑📸❤ Mid Tim...\n",
       "1  Обещала вам пост, как выглядит типичный рабочи...\n",
       "2  Mia had a great morning despite the little sle...\n",
       "3  ᴛᴀsᴛʏ ᴛʜᴜʀsᴅᴀʏ, ᴀɴᴅ ᴛᴏᴅᴀʏ ᴡᴇ ᴠᴇɴᴛᴜʀᴇ ᴅᴏᴡɴ ᴛᴏ ᴘ...\n",
       "4  EMBAJADORA 50/50/25 . Gracias a la Organizació...\n",
       "5  Such an incredible #Coachella weekend with the...\n",
       "6  حتمن یادتون میاد که یه موقعی این بحث خیلی داغ ..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"caption\").limit(7).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "878d7924",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"caption\", translate(\"caption\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c3b0a02",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My newest - 21 st magazine cover😊👸🏼👑📸❤ Mid Tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I promised you a post what a typical working d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mia had a great morning despite the little sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ᴛᴀsᴛʏ ᴛʜᴜʀsᴅᴀʏ, ᴀɴᴅ ᴛᴏᴅᴀʏ ᴡᴇ ᴠᴇɴᴛᴜʀᴇ ᴅᴏᴡɴ ᴛᴏ ᴘ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMBASSADOR 50/50/25. Thanks to the @behobia_ss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Such an incredible #Coachella weekend with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You must remember that at one time this debate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption\n",
       "0  My newest - 21 st magazine cover😊👸🏼👑📸❤ Mid Tim...\n",
       "1  I promised you a post what a typical working d...\n",
       "2  Mia had a great morning despite the little sle...\n",
       "3  ᴛᴀsᴛʏ ᴛʜᴜʀsᴅᴀʏ, ᴀɴᴅ ᴛᴏᴅᴀʏ ᴡᴇ ᴠᴇɴᴛᴜʀᴇ ᴅᴏᴡɴ ᴛᴏ ᴘ...\n",
       "4  AMBASSADOR 50/50/25. Thanks to the @behobia_ss...\n",
       "5  Such an incredible #Coachella weekend with the...\n",
       "6  You must remember that at one time this debate..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"caption\").limit(7).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385edcc3",
   "metadata": {},
   "source": [
    "### Accessibility Caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcce3d9",
   "metadata": {},
   "source": [
    "We will now take a look at <code>accessibility_caption</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef0a6fb7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>owner_id</th>\n",
       "      <th>owner_username</th>\n",
       "      <th>location_id</th>\n",
       "      <th>location_name</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>commenters_id</th>\n",
       "      <th>commenters_username</th>\n",
       "      <th>tagged_users_id</th>\n",
       "      <th>tagged_users_username</th>\n",
       "      <th>caption</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>accessibility_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1764716511598871662</td>\n",
       "      <td>3442535492</td>\n",
       "      <td>couple_around_the_world</td>\n",
       "      <td>213045606</td>\n",
       "      <td>St. Paul's Cathedral</td>\n",
       "      <td>615</td>\n",
       "      <td>53</td>\n",
       "      <td>[5613403460, 1520835524, 5064849724, 558125139...</td>\n",
       "      <td>passiontravelers, brisbanefamilyexplorers, yuk...</td>\n",
       "      <td>[18653141, 218204713, 221827472, 303273692, 32...</td>\n",
       "      <td>londonarchitecture, visitengland, architecture...</td>\n",
       "      <td>Sometimes you just have to stop and admire the...</td>\n",
       "      <td></td>\n",
       "      <td>Image may contain: one or more people, people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1928919091570114766</td>\n",
       "      <td>237255794</td>\n",
       "      <td>niko0o0o</td>\n",
       "      <td>272675853354272</td>\n",
       "      <td>Iranmehr Hospital   بیمارستان ایرانمهر</td>\n",
       "      <td>8770</td>\n",
       "      <td>353</td>\n",
       "      <td>[1557411337, 189702389, 1450110238, 43489340, ...</td>\n",
       "      <td>mahsa_bano_v, kolinoosh, pegah_vrz, omiddg55, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>• I do not know if you have a bitter experienc...</td>\n",
       "      <td></td>\n",
       "      <td>Image may contain: indoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1783962564531625928</td>\n",
       "      <td>28431316</td>\n",
       "      <td>irina_ls</td>\n",
       "      <td>3001453</td>\n",
       "      <td>Millennium Park</td>\n",
       "      <td>2090</td>\n",
       "      <td>44</td>\n",
       "      <td>[28431316, 11712605, 465298586, 1519223122, 15...</td>\n",
       "      <td>irina_ls, tycolllins, el.voroshilova, gubanova...</td>\n",
       "      <td>[222301553, 225180463, 1101825364, 1642751093,...</td>\n",
       "      <td>choosechicago, chicagobucketlist, insta_chicag...</td>\n",
       "      <td>🎶rita ora - girls ⠀ who am i if not a princess...</td>\n",
       "      <td>usa_withirinls, иринблогпроньюйорк</td>\n",
       "      <td>Image may contain: 2 people, outdoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1773896275306061138</td>\n",
       "      <td>21474914</td>\n",
       "      <td>alleksana</td>\n",
       "      <td>215231527</td>\n",
       "      <td>Hampstead, United Kingdom</td>\n",
       "      <td>2202</td>\n",
       "      <td>64</td>\n",
       "      <td>[27735783, 52456658, 4111776536, 179448265, 23...</td>\n",
       "      <td>verchik_magjanova, victo_somewhere, suitcaseof...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>When you unexpectedly hit the club on Saturday...</td>\n",
       "      <td></td>\n",
       "      <td>Image may contain: plant, tree, flower and out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1825519529327637742</td>\n",
       "      <td>1300539481</td>\n",
       "      <td>dan_stagen</td>\n",
       "      <td>218214254</td>\n",
       "      <td>Oía, Kikladhes, Greece</td>\n",
       "      <td>1241</td>\n",
       "      <td>42</td>\n",
       "      <td>[5913421695, 269042164, 350209917, 288085091, ...</td>\n",
       "      <td>takemyhearteverywhere, leksa_diary, kasia_life...</td>\n",
       "      <td>[233942711, 342711792, 449270888, 515489346, 9...</td>\n",
       "      <td>visitgreecegr, paul_hewitt, wu_greece, visitgr...</td>\n",
       "      <td>ALL THE TRUTH ABOUT SANTORINI🇬🇷 \"Part ||\" ⠀⠀ W...</td>\n",
       "      <td>stagen_santorini</td>\n",
       "      <td>Image may contain: sky, ocean, outdoor and water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               post_id    owner_id           owner_username      location_id  \\\n",
       "0  1764716511598871662  3442535492  couple_around_the_world        213045606   \n",
       "1  1928919091570114766   237255794                 niko0o0o  272675853354272   \n",
       "2  1783962564531625928    28431316                 irina_ls          3001453   \n",
       "3  1773896275306061138    21474914                alleksana        215231527   \n",
       "4  1825519529327637742  1300539481               dan_stagen        218214254   \n",
       "\n",
       "                            location_name  likes_count  comments_count  \\\n",
       "0                    St. Paul's Cathedral          615              53   \n",
       "1  Iranmehr Hospital   بیمارستان ایرانمهر         8770             353   \n",
       "2                         Millennium Park         2090              44   \n",
       "3               Hampstead, United Kingdom         2202              64   \n",
       "4                  Oía, Kikladhes, Greece         1241              42   \n",
       "\n",
       "                                       commenters_id  \\\n",
       "0  [5613403460, 1520835524, 5064849724, 558125139...   \n",
       "1  [1557411337, 189702389, 1450110238, 43489340, ...   \n",
       "2  [28431316, 11712605, 465298586, 1519223122, 15...   \n",
       "3  [27735783, 52456658, 4111776536, 179448265, 23...   \n",
       "4  [5913421695, 269042164, 350209917, 288085091, ...   \n",
       "\n",
       "                                 commenters_username  \\\n",
       "0  passiontravelers, brisbanefamilyexplorers, yuk...   \n",
       "1  mahsa_bano_v, kolinoosh, pegah_vrz, omiddg55, ...   \n",
       "2  irina_ls, tycolllins, el.voroshilova, gubanova...   \n",
       "3  verchik_magjanova, victo_somewhere, suitcaseof...   \n",
       "4  takemyhearteverywhere, leksa_diary, kasia_life...   \n",
       "\n",
       "                                     tagged_users_id  \\\n",
       "0  [18653141, 218204713, 221827472, 303273692, 32...   \n",
       "1                                                 []   \n",
       "2  [222301553, 225180463, 1101825364, 1642751093,...   \n",
       "3                                                 []   \n",
       "4  [233942711, 342711792, 449270888, 515489346, 9...   \n",
       "\n",
       "                               tagged_users_username  \\\n",
       "0  londonarchitecture, visitengland, architecture...   \n",
       "1                                                      \n",
       "2  choosechicago, chicagobucketlist, insta_chicag...   \n",
       "3                                                      \n",
       "4  visitgreecegr, paul_hewitt, wu_greece, visitgr...   \n",
       "\n",
       "                                             caption  \\\n",
       "0  Sometimes you just have to stop and admire the...   \n",
       "1  • I do not know if you have a bitter experienc...   \n",
       "2  🎶rita ora - girls ⠀ who am i if not a princess...   \n",
       "3  When you unexpectedly hit the club on Saturday...   \n",
       "4  ALL THE TRUTH ABOUT SANTORINI🇬🇷 \"Part ||\" ⠀⠀ W...   \n",
       "\n",
       "                             hashtags  \\\n",
       "0                                       \n",
       "1                                       \n",
       "2  usa_withirinls, иринблогпроньюйорк   \n",
       "3                                       \n",
       "4                    stagen_santorini   \n",
       "\n",
       "                               accessibility_caption  \n",
       "0  Image may contain: one or more people, people ...  \n",
       "1                          Image may contain: indoor  \n",
       "2               Image may contain: 2 people, outdoor  \n",
       "3  Image may contain: plant, tree, flower and out...  \n",
       "4   Image may contain: sky, ocean, outdoor and water  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"accessibility_caption\") != '') & \n",
    "          (col(\"accessibility_caption\") != 'No photo description available.')).limit(5).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a75fa8e",
   "metadata": {},
   "source": [
    "Noticed location_name not in english, lets first translate location_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c40b28b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>St. Paul's Cathedral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iranmehr Hospital   بیمارستان ایرانمهر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Millennium Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hampstead, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oía, Kikladhes, Greece</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            location_name\n",
       "0                    St. Paul's Cathedral\n",
       "1  Iranmehr Hospital   بیمارستان ایرانمهر\n",
       "2                         Millennium Park\n",
       "3               Hampstead, United Kingdom\n",
       "4                  Oía, Kikladhes, Greece"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"location_name\").filter((col(\"accessibility_caption\") != '') & \n",
    "          (col(\"accessibility_caption\") != 'No photo description available.')).limit(5).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d634cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"location_name\", translate(\"location_name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1879bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>St. Paul's Cathedral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iranmehr Hospital. Iranmehr Hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Millennium Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hampstead, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oía, Kikladhes, Greece</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          location_name\n",
       "0                  St. Paul's Cathedral\n",
       "1  Iranmehr Hospital. Iranmehr Hospital\n",
       "2                       Millennium Park\n",
       "3             Hampstead, United Kingdom\n",
       "4                Oía, Kikladhes, Greece"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"location_name\").filter((col(\"accessibility_caption\") != '') & \n",
    "          (col(\"accessibility_caption\") != 'No photo description available.')).limit(5).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d6f05",
   "metadata": {},
   "source": [
    "In the previous section the first 20 rows of the column <code>accessibility_caption</code> were missing values, let's see how many in total are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c811b7de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3855"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"accessibility_caption\") == '')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d979c02",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12117"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"accessibility_caption\") == 'No photo description available.')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d495291",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32621"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"accessibility_caption\") != '') &\n",
    "          (col(\"accessibility_caption\") != 'No photo description available.')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234c905",
   "metadata": {},
   "source": [
    "<code>TODO:</code> conclude why accessibility_caption still useful for us even if many are missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121b3c7f",
   "metadata": {},
   "source": [
    "## 4. Content Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cac802",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pandas_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da68c44b",
   "metadata": {},
   "source": [
    "Combine features for similarity extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053e7e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "combined_features = pandas_df[\"location_name\"] + \" \" + pandas_df[\"hashtags\"] + \" \" + \\\n",
    "                    pandas_df[\"caption\"] + \" \" + pandas_df[\"accessibility_caption\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c54d813",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(combined_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a1ed6",
   "metadata": {},
   "source": [
    "Use TF-IDF Vectorizer to convert the text data to feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5161ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b95fed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_vectors = vectorizer.fit_transform(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0df26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(feature_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a308fed2",
   "metadata": {},
   "source": [
    "Find cosine similarity of feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3f8c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cfa7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(similarity.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a16c5",
   "metadata": {},
   "source": [
    "Take User Input for a location. We have chosen 'San Diego' as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d398f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_input = input('Please input a location: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4a6d9",
   "metadata": {},
   "source": [
    "Get all the locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a52524",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "locations_list = pandas_df[\"location_name\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9304fdcd",
   "metadata": {},
   "source": [
    "Find the closest match to our user inputted location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab23ca5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "find_closest_match = difflib.get_close_matches(user_input, locations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa0a945",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "close_match = find_closest_match[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe845c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(close_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e7eb6",
   "metadata": {},
   "source": [
    "Find the index of the closest match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d96f9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_close_match = pandas_df.index[pandas_df[\"location_name\"] == close_match][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ef8eb0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(index_close_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff55ff29",
   "metadata": {},
   "source": [
    "Get the similarity scores of all the locations to our closest match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0652674",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "similarity_score = list(enumerate(similarity[index_close_match]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f49a35",
   "metadata": {},
   "source": [
    "Preview first 5 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7127265",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(similarity_score[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a501de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6cc4d",
   "metadata": {},
   "source": [
    "Graph showing the locations and their similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b37191c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(*zip(*similarity_score))\n",
    "plt.title(\"Similarity Scores for All Posts\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Similarity Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89b407e",
   "metadata": {},
   "source": [
    "Sort our similarity_score array from highest to lowest similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8831d6e7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sorted_locations = sorted(similarity_score, key = lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6394edf9",
   "metadata": {},
   "source": [
    "Preview first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d89e44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(sorted_locations[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6e61bf",
   "metadata": {},
   "source": [
    "Show the top 5 recommended locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba0ed31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Top 5: Locations suggested for you: \\n\")\n",
    "x = []\n",
    "y = []\n",
    "i = 1\n",
    "for location in sorted_locations:\n",
    "    index = location[0]\n",
    "    location_name = pandas_df[pandas_df.index == index][\"location_name\"].values\n",
    "    if (i <= 5):\n",
    "        x.append(location_name[0])\n",
    "        y.append(location[1])\n",
    "        print(i,'.',location_name[0])\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8ac89e",
   "metadata": {},
   "source": [
    "Graph showing the top 5 suggested location and their similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d36ba6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(x, y, linestyle='-')\n",
    "ax.set_ylabel(\"Similarity Score\")\n",
    "ax.set_xlabel(\"Location Name\")\n",
    "ax.set_title(\"Top 5 Locations Recommended\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba523a",
   "metadata": {},
   "source": [
    "## 5. Latent Factor Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b31b5a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data, labelCol):\n",
    "    predictions = model.transform(data)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=labelCol,\n",
    "                                predictionCol=\"prediction\")\n",
    "    return evaluator.evaluate(predictions)\n",
    "\n",
    "def flatten_(v):\n",
    "    try:\n",
    "        return float(v[0])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "flatten = udf(flatten_, DoubleType())\n",
    "\n",
    "tst_rmse = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195a4c3",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a361929d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LF_df = df.select(\"owner_id\", \"location_id\")\n",
    "LF_df = LF_df.withColumn(\"owner_id\", col(\"owner_id\").cast(IntegerType())).\\\n",
    "    withColumn(\"location_id\", col(\"location_id\").cast(IntegerType())).\\\n",
    "    withColumnRenamed(\"owner_id\", \"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "639b2ceb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LF1 = LF_df.groupby(\"user_id\", \"location_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "220ebc0f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error:  1.7561659640983387\n"
     ]
    }
   ],
   "source": [
    "(training, test) = LF1.randomSplit([0.8, 0.2], seed=SEED)\n",
    "\n",
    "als = ALS(maxIter=5, regParam=0.01, rank=25, coldStartStrategy=\"drop\",\n",
    "          userCol=\"user_id\", itemCol=\"location_id\", ratingCol=\"count\").setSeed(SEED)\n",
    "model = als.fit(training)\n",
    "\n",
    "test_rmse = evaluate(model, test, \"count\")\n",
    "\n",
    "tst_rmse.append(test_rmse)\n",
    "\n",
    "print(\"Root mean squared error: \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c16c3d",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "276a4e22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tagged_df = df.select(explode(df.tagged_users_id).alias(\"user_id\"),\"location_id\")\n",
    "tagged_df = tagged_df.withColumn(\"user_id\", col(\"user_id\").cast(IntegerType())).\\\n",
    "    withColumn(\"location_id\", col(\"location_id\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb6622d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LF2 = LF_df.union(tagged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83c6e1a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LF2 = LF2.groupby(\"user_id\", \"location_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c9a5afd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error:  1.3162391951559242\n"
     ]
    }
   ],
   "source": [
    "(training, test) = LF2.randomSplit([0.8, 0.2], seed=SEED)\n",
    "\n",
    "als = ALS(maxIter=5, regParam=0.01, rank=25, coldStartStrategy=\"drop\",\n",
    "          userCol=\"user_id\", itemCol=\"location_id\", ratingCol=\"count\").setSeed(SEED)\n",
    "model = als.fit(training)\n",
    "\n",
    "test_rmse = evaluate(model, test, \"count\")\n",
    "\n",
    "tst_rmse.append(test_rmse)\n",
    "\n",
    "print(\"Root mean squared error: \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a424b54",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c358aa2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LF_df = df.select(\"owner_id\", \"location_id\", \"location_name\", \"likes_count\")\n",
    "LF_df = LF_df.withColumn(\"owner_id\", col(\"owner_id\").cast(IntegerType())).\\\n",
    "    withColumn(\"location_id\", col(\"location_id\").cast(IntegerType())).\\\n",
    "    withColumnRenamed(\"owner_id\", \"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c917a362",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tagged_df = df.select(explode(df.tagged_users_id).alias(\"user_id\"),\"location_id\", \"location_name\", \"likes_count\")\n",
    "tagged_df = tagged_df.withColumn(\"user_id\", col(\"user_id\").cast(IntegerType())).\\\n",
    "    withColumn(\"location_id\", col(\"location_id\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "595b4a2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LF3 = LF_df.union(tagged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da848f7c",
   "metadata": {},
   "source": [
    "Create a dictionary of locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256a3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_id = LF3.select(\"location_id\").collect()\n",
    "location_name = LF3.select(\"location_name\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ff381",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc_id, loc_name in zip(location_id, location_name):\n",
    "    if loc_id[0] in LOCATIONS:\n",
    "        pass\n",
    "    else:\n",
    "        LOCATIONS[loc_id[0]] = loc_name[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43908a96",
   "metadata": {},
   "source": [
    "Group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec2b5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LF3 = LF3.groupby(\"user_id\", \"location_id\").agg(count('*').alias(\"count\"),\\\n",
    "                                                sum(LF3.likes_count).\\\n",
    "                                                alias(\"sum_likes\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c14a1c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LF3 = LF3.withColumn(\"bias_count\", col(\"count\") + col(\"sum_likes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fb6b54",
   "metadata": {},
   "source": [
    "Convert df column to vector to be able to fit and transform with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a643f2c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"bias_count\"], outputCol=\"bias_count_vec\")\n",
    "\n",
    "LF3 = assembler.transform(LF3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9494a5d5",
   "metadata": {},
   "source": [
    "Rescaling rating to range [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9911f9e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(training, test) = LF3.randomSplit([0.8, 0.2], seed=SEED)\n",
    "\n",
    "scaler = MinMaxScaler(min=0.0, max=5.0, inputCol=\"bias_count_vec\", outputCol=\"norm_count\")\n",
    "\n",
    "model = scaler.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5ac15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training = model.transform(training)\n",
    "test = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48047993",
   "metadata": {},
   "source": [
    "Flatten Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c86c4e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training = training.withColumn(\"norm_count\", flatten(\"norm_count\"))\n",
    "test = test.withColumn(\"norm_count\", flatten(\"norm_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a998463",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "als = ALS(maxIter=5, regParam=0.01, rank=25, coldStartStrategy=\"drop\",\n",
    "          userCol=\"user_id\", itemCol=\"location_id\", ratingCol=\"norm_count\").setSeed(SEED)\n",
    "model = als.fit(training)\n",
    "\n",
    "test_rmse = evaluate(model, test, \"norm_count\")\n",
    "\n",
    "tst_rmse.append(test_rmse)\n",
    "\n",
    "print(\"Root mean squared error: \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daab830",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a4ceb7",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff5d7c",
   "metadata": {},
   "source": [
    "60% Training, 20% Validation, 20% Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b137a2",
   "metadata": {},
   "source": [
    "Not my goal :( wanted to do with 5 parameters but as of 3 parameters goes out of memory\n",
    "\n",
    "<code>java.lang.OutOfMemoryError: GC overhead limit exceeded</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f80a2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "regParams = [0.01, 0.1]\n",
    "iterations = [5, 10]\n",
    "ranks = [50, 70]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac372244",
   "metadata": {},
   "source": [
    "Rescaling rating to range [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b8211",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(training, test) = LF3.randomSplit([0.8, 0.2], seed=SEED)\n",
    "\n",
    "scaler = MinMaxScaler(min=0.0, max=5.0, inputCol=\"bias_count_vec\", outputCol=\"norm_count\")\n",
    "\n",
    "scaler_model = scaler.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec85fa0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training = scaler_model.transform(training)\n",
    "test = scaler_model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd73a3",
   "metadata": {},
   "source": [
    "Flatten Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87ce59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training = training.withColumn(\"norm_count\", flatten(\"norm_count\"))\n",
    "test = test.withColumn(\"norm_count\", flatten(\"norm_count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a20c5b",
   "metadata": {},
   "source": [
    "collectSubModels = True to collect all submodels created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764bc9cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "als = ALS(coldStartStrategy=\"drop\",userCol=\"user_id\", itemCol=\"location_id\", ratingCol=\"norm_count\").setSeed(SEED)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"norm_count\", predictionCol=\"prediction\")\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(als.regParam, regParams) \\\n",
    "    .addGrid(als.maxIter, iterations)\\\n",
    "    .addGrid(als.rank, ranks)\\\n",
    "    .build()\n",
    "\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=als,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=evaluator,\n",
    "                           trainRatio=0.75,\n",
    "                           collectSubModels=True,\n",
    "                           seed = SEED)\n",
    "\n",
    "model = tvs.fit(training)\n",
    "\n",
    "best_model = model.bestModel\n",
    "\n",
    "test_rmse = evaluate(best_model, test, \"norm_count\")\n",
    "\n",
    "tst_rmse.append(test_rmse)\n",
    "\n",
    "print(\"Root mean squared error: \", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8897ec58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(model.validationMetrics)\n",
    "plt.title(\"Validation performance\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Root mean squared error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e54eab",
   "metadata": {},
   "source": [
    "Submodel at index 3 is the best model with the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b47360",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert best_model._java_obj.parent().getRegParam() == model.subModels[3]._java_obj.parent().getRegParam()\n",
    "assert best_model._java_obj.parent().getMaxIter() == model.subModels[3]._java_obj.parent().getMaxIter()\n",
    "assert best_model._java_obj.parent().getRank() == model.subModels[3]._java_obj.parent().getRank()\n",
    "\n",
    "print(\"regParam: \", best_model._java_obj.parent().getRegParam())\n",
    "print(\"maxIter: \", best_model._java_obj.parent().getMaxIter())\n",
    "print(\"Rank: \", best_model._java_obj.parent().getRank())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7964b65",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d3357a",
   "metadata": {},
   "source": [
    "Rescaling rating to range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b93ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(training, test) = LF3.randomSplit([0.8, 0.2], seed=SEED)\n",
    "\n",
    "scaler = MinMaxScaler(min=0.0, max=1.0, inputCol=\"bias_count_vec\", outputCol=\"norm_count\")\n",
    "\n",
    "scaler_model = scaler.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fedfab5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training = scaler_model.transform(training)\n",
    "test = scaler_model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650a228a",
   "metadata": {},
   "source": [
    "Flatten Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cccaae1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training = training.withColumn(\"norm_count\", flatten(\"norm_count\"))\n",
    "test = test.withColumn(\"norm_count\", flatten(\"norm_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef6a20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "als = ALS(maxIter=10, regParam=0.01, rank=70, coldStartStrategy=\"drop\",\n",
    "          userCol=\"user_id\", itemCol=\"location_id\", ratingCol=\"norm_count\").setSeed(SEED)\n",
    "model = als.fit(training)\n",
    "\n",
    "test_rmse = evaluate(model, test, \"norm_count\")\n",
    "\n",
    "tst_rmse.append(test_rmse)\n",
    "\n",
    "print(\"Root mean squared error: \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6acf6f4",
   "metadata": {},
   "source": [
    "### Model performances on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8295052",
   "metadata": {},
   "source": [
    "|Models|RMSE|\n",
    "|:---:|:---:|\n",
    "|M1|1.786|\n",
    "|M2|1.329|\n",
    "|M3|0.052|\n",
    "|M4|0.050|\n",
    "|M5|0.012|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5737f0e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = ['M1', 'M2', 'M3', 'M4', 'M5']\n",
    "plt.plot(x, tst_rmse)\n",
    "plt.title(\"Testing performance\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Root mean squared error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d939b894",
   "metadata": {},
   "source": [
    " Before looking at the recommendation list, let’s have a look at what this user preferences currently are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c4934",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LF3.select(\"location_name\").filter(col(\"user_id\") == 398526345).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19841e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user = LF3.select(als.getUserCol()).filter(col(\"user_id\") == 398526345).limit(1)\n",
    "userRec = model.recommendForUserSubset(user, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14f538",
   "metadata": {},
   "source": [
    "And here are the recommendations from our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8869b21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Top 5 locations recommended to user 398526345\")\n",
    "for i, loc in enumerate(userRec.collect()[0][\"recommendations\"]):\n",
    "    print(i+1, LOCATIONS.get(loc[\"location_id\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
